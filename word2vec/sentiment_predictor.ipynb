{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0f56cffdfb8a3c28fb5d73307836774a10a5a42bd9311c7e679cf966abb5d38fa",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250/2\")\n",
    "clf = keras.models.load_model('model84.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(\"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\", ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "          tokens.append(token)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def encoding(tweet):\n",
    "    tweet = preprocess(tweet)\n",
    "    tokens = tweet.split(\" \")\n",
    "    embedding = []\n",
    "    for token in tokens:\n",
    "        embedding.append(embed([token]).numpy()[0])\n",
    "\n",
    "    embedding = np.array(embedding)\n",
    "    padded_tweet = padding(embedding)\n",
    "    return padded_tweet\n",
    "\n",
    "def padding(encoded_tweet):\n",
    "    count = 70 - encoded_tweet.shape[0]\n",
    "    pad = np.zeros((1,250))\n",
    "    for i in range(count):\n",
    "        encoded_tweet = np.concatenate((pad,encoded_tweet), axis=0)\n",
    "    return encoded_tweet\n",
    "\n",
    "def processed_tweets(tweet):\n",
    "    x = []\n",
    "    enc = encoding(tweet)\n",
    "    x.append(enc)\n",
    "    x = np.array(x)\n",
    "    return x\n",
    "\n",
    "def predict(tweet, model):\n",
    "    prediction = model.predict(processed_tweets(tweet))[0][0]\n",
    "    result =  1.0 if prediction > 0.5 else 0.0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Execute all cells above this once\n",
    "\n",
    "call predict function to get sentiment\n",
    "\n",
    "input type :-\n",
    "    tweet - string\n",
    "    model - keras model\n",
    "\n",
    "return type :- \n",
    "    float\n",
    "\n",
    "refer the example below\n",
    "'''\n",
    "\n",
    "predict('very good government', clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}